{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: CNN Part 2\n",
    "\n",
    "## Refer the tutorial notebook for CNN part 2 to complete the following exercises\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an accurate image classifier with ResNet 50 CNN using transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "from __future__ import absolute_import, division, print_function # make it compatible w Python 2\n",
    "import os\n",
    "import h5py # to handle weights\n",
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# !pip install opencv-python \n",
    "import cv2 #conda install open-cv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "\n",
    "TRAIN_DIR = './data/train/'\n",
    "VAL_DIR = './data/validation/'\n",
    "TEST_DIR = './data/test/' #mixed cats and dogs\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "n_train_samples = 2000\n",
    "n_validation_samples = 800\n",
    "n_epoch = 25\n",
    "n_test_samples = 100\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pre-trained ResNet 50 and save the bottleneck features as numpy files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Add the code for loading a pre-trained ResNet-50 CNN trained on ImageNet dataset without the top layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for saving bottleneck features\n",
    "#  Run model once to record the bottleneck features using image data generators:\n",
    "\n",
    "def save_bottleneck_features():\n",
    "\n",
    "    from tensorflow.keras import applications\n",
    "    \n",
    "    # write the code to load ResNe50 \n",
    "\n",
    "    \n",
    "    \n",
    "    print('TensorFlow ResNet-50 model architecture loaded')\n",
    "\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    def generate_features(DIR,n_samples,name_str):\n",
    "        '''This is a generator that will read pictures found in\n",
    "        subfolders of 'data/*', and indefinitely generate\n",
    "        batches of rescaled images used to predict\n",
    "        the bottleneck features of the images once\n",
    "        using model.predict_generator(**args**)'''\n",
    "        \n",
    "        print('Generate '+name_str+' image features')\n",
    "\n",
    "        generator = datagen.flow_from_directory(\n",
    "            DIR,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=1,\n",
    "            class_mode=None,\n",
    "            shuffle=False)\n",
    "\n",
    "        features = model.predict_generator(generator, n_samples,verbose=True)\n",
    "\n",
    "        np.save('features_'+name_str+'.npy', features) # save bottleneck features to file\n",
    "    \n",
    "    generate_features(TEST_DIR, n_test_samples, 'test')\n",
    "    #generate_features(TRAIN_DIR, n_train_samples, 'train')\n",
    "    #generate_features(VAL_DIR, n_validation_samples, 'validation')\n",
    "    \n",
    "    print('\\nDone! Bottleneck features have been saved')\n",
    "\n",
    "print('This has been done before the lecture! Takes 5+ mins to run.')\n",
    "save_bottleneck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain class labels and binary classification for validation data\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_gen = datagen.flow_from_directory(VAL_DIR,target_size=(img_width, img_height),\n",
    "                                        batch_size=32,class_mode=None,shuffle=False)\n",
    "\n",
    "val_labels = val_gen.classes\n",
    "\n",
    "print('\\nClassifications:\\n',val_gen.class_indices)\n",
    "print('\\nClass labels:\\n',val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in bottleneck features\n",
    "# Run the code below to train your CNN with the training data\n",
    "\n",
    "train_data = np.load('features_train.npy')\n",
    "# the features were saved in order, so recreating the labels is easy\n",
    "train_labels = np.array([0] * (n_train_samples // 2) + [1] * (n_train_samples // 2))\n",
    "\n",
    "validation_data = np.load('features_validation.npy')\n",
    "# same as val_labels above\n",
    "validation_labels = np.array([0] * (n_validation_samples // 2) + [1] * (n_validation_samples // 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Add the following top layers:\n",
    "1. Dense layer with 1024 units and relu activation\n",
    "2. Dropout of 0.5\n",
    "3. output layer with 1 unit and sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "\n",
    "# add the remaining layers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Compile the model with necessary loss, optimizer and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= ,\n",
    "              loss= ,\n",
    "              metrics= )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_WEIGHTS_FILE = 'resnet50-best-weights.h5'\n",
    "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE, monitor='val_accuracy', verbose=1, save_best_only=True)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Fit the model on the new features as training and validation data and fill in the missing arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x= , \n",
    "                    y= ,\n",
    "                    epochs=25, \n",
    "                    batch_size=32,\n",
    "                    validation_data= ,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.model.load_weights('resnet50-best-weights.h5')\n",
    "model = history.model\n",
    "model.summary()\n",
    "\n",
    "acc = pd.DataFrame({'epoch': range(1,n_epoch+1),\n",
    "                    'training': history.history['accuracy'],\n",
    "                    'validation': history.history['val_accuracy']})\n",
    "ax = acc.plot(x='epoch', figsize=(10,6), grid=True)\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_ylim([0.7,1.0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative\n",
    "print('Model accuracy on validation set:')\n",
    "\n",
    "model.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
