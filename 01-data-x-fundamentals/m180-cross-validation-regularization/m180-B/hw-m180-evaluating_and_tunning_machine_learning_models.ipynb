{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data-x](https://raw.githubusercontent.com/afo/data-x-plaksha/master/imgsource/dx_logo.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**References and Additional Resources**\n",
    "<br>\n",
    "\n",
    "\n",
    "> [ScikitLearn Regression Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)<br>\n",
    "> [ScikitLearn Classification Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "#### NAME:\n",
    "\n",
    "#### STUDENT ID:\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework - Model Evaluation\n",
    "\n",
    "It is now your turn to hone your model evaluation skills, and develop a logical and replicable machine learning model evaluation procedure. The skills you develop in this homework assignment will come in handy as you transition to more complicated models and datasets over the coming weeks. \n",
    "\n",
    "Using one of the following toy data sets easily loaded from the ScikitLearn library, perform an end-to-end model evaluation.\n",
    "\n",
    "> [Boston House Prices Dataset (Regression)](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston)<br>\n",
    "> [Diabetes Dataset (Regression)](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes)<br>\n",
    "> [Breast Cancer Wisconsin Dataset (Classification)](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer)<br>\n",
    "> [Iris Dataset (Classification)](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine)<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "**General Recommendations:** \n",
    "> 1. Your code should be legible and well documented.\n",
    "> 2. Your code should seek to 'tell a story' of how you logically progressed through the evaluation process. Not sure how to do such a thing. Here are [some examples](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks)\n",
    "> 3. Site your sources in a comment line on the code you borrowed, or by referencing it in a markdown cell immediately below.\n",
    "> 4. Work on asking good questions, interpreting your models, visualizing your experiments, and using visualization and clear language to explain your decisions -- effort to master these areas will pay great dividends in the long run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries here or as you go\n",
    "# feel free to use the visualization library of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Load and Preprocess Data\n",
    "\n",
    "Using what you learned from the m180_evaluating_and_improving_machine_learning_models notebook, prepare your data for modeling.  \n",
    "0. Set a random seed globally for reproducibility.\n",
    "1. Load and inspect your data. \n",
    "2. Check for any issues that may influence your model (e.g. heteroscedasticity, data inbalance, missing values, etc.) and correct the issue(s).\n",
    "3. Clearly explain how you identified 2 or create two plots that show how you identified 2 above: One should show how you identified the issue, the other what the result of your correction was.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (use as many cells as you need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (use as many cells as you need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (use as many cells as you need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Establish a Baseline Model\n",
    "\n",
    "> 1. Pick a baseline model and fit the model. \n",
    "> 2. Elect 2 the metrics you will use to evaluate this baseline model against other models (e.g. RMSE, Accuracy, etc.) and print them out.\n",
    "> 3. Write a brief description of why you chose the baseline model you did and comment on the metrics you will be using to compare your baseline against alternate models. \n",
    "> 4. Visualize your metrics of interest (Optional for Undergrads; Required for Grad Students)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (use as many cells as you need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (use as many cells as you need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (use as many cells as you need)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Model Selection\n",
    "\n",
    "> 1. Pick two alternative models and train them (do not pre-tune the alternative models). \n",
    "> 2. Compare your alternatives to the baseline model using the metrics you chose previously.\n",
    "> 3. Write a brief description of why you chose the two alternative models, and elaborate on why a particular model did better on the particular data set you used, as well as how you discerned this.\n",
    "> 4. Visualize your metrics of interest accross all models (Optional for Undergrads; Required for Grad Students)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (use as many cells as you need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (use as many cells as you need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (use as many cells as you need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Model Evaluation and Tunning\n",
    "\n",
    "> 1. Using the best model from your previous work, use metrics and visualizations to diagnose problems with your model.\n",
    "> 2. Propose solutions to any issues to your model and implement them (e.g. High bias --> feature engineering; High variance --> regularization). Breifly explain your reasoning.\n",
    "> 3. Iteratively repeat process until you deem appropriate to stop. Explain how you knew when to stop the iterative process.\n",
    "> 4. Write a bried summary of the entire process, key observations, and conclusions. For good examples of how to create interesting and engaging jupyter notebooks, see [here](https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks)\n",
    "\n",
    "**Note:** at this time, take care to only implement one change at a time and re-evaluate your model prior to making any additional changes. Try to adhere to an [Occam Learning](https://en.wikipedia.org/wiki/Occam_learning) approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (use as many cells as you need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (use as many cells as you need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (use as many cells as you need)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "Please submit your the following via the instructed method (lecture or Syllabus): \n",
    "\n",
    ">(1) A copy of your work, either a downloaded notebook or a pdf, by the assignment deadline\n",
    "\n",
    "<br>\n",
    "\n",
    "**Note:** Don't gorget to restart your kernel prior to extracting your data.\n",
    "\n",
    ">```Kernel --> Restart Kernel and Run all Cells```<br>\n",
    ">```File --> Export Notebooks As --> PDF``` (or as instructed)\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
