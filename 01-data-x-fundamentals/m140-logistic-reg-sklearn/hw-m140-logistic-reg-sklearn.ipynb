{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Logistic Regression Classification with SciKit-Learn\n",
    "\n",
    "This homework demonstrates how SciKit-Learn can be used to build logistic regression models, improve models with feature scaling, and measure performance. You'll predict energy load usage and build a simple handwriten digit classifier.\n",
    "\n",
    "***Summary***\n",
    "1. [Understanding the Data](#understand-the-data)\n",
    "2. [Classification with Feature Scaling](#feature-scaling)\n",
    "3. [Precision, Recall, and Confusion Matrix](#confusion-matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id='understand-the-data'></a>\n",
    "## 1. Understanding the Data\n",
    "\n",
    "The dataset was created by Angeliki Xifara ( Civil/Structural Engineer) and was processed by Athanasios Tsanas, Oxford Centre for Industrial and Applied Mathematics, University of Oxford, UK). The Data file should be next to your notebook file called : `Energy.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1     X2     X3      X4   X5  X6   X7  X8     Y1\n",
       "0  0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55\n",
       "1  0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55\n",
       "2  0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55\n",
       "3  0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55\n",
       "4  0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path='./Energy.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Check top 5 rows of the data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains eight attributes of a building (or features, denoted by `X1` ... `X8`) and response being the heating load on the building, `Y1`. \n",
    "\n",
    "* `X1` relative Compactness \n",
    "* `X2`\tSurface Area \n",
    "* `X3`\tWall Area \n",
    "*  `X4`\tRoof Area \n",
    "*  `X5`\tOverall Height \n",
    "* `X6`\tOrientation \n",
    "*  `X7`\tGlazing Area \n",
    "*  `X8`\tGlazing Area Distribution \n",
    "*  `Y1`\tHeating Load "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Q1 a) Describe the distribution range of the data features. Create a dataframe where the columns are data features and response variables and the rows indices are count, mean, min, and max (in *this exact* order). Store the output of the above operation result in a new variable called `distribution`.**\n",
    " \n",
    "Your plotted image should look like this:\n",
    " \n",
    "<img src=\"assets/q1a_expected.PNG\" width=\"500\" />\n",
    "    \n",
    "*Hint:* Use [`pandas.DataFrame.describe`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "distribution = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q1 b) Check if there are any NaN/null values. Store the anaswer as boolean True or False in the variable `any_nulls`.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "any_nulls = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1 c) Separate the data into features and output labels. Take the columns labelled `X1` to `X8` and store them in a new variable called `X`. Store the column `Y1` into a new variable called `Y`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "X = ...\n",
    "Y = ...\n",
    "\n",
    "#print('X:')\n",
    "#display(X.head())\n",
    "#print('Y:')\n",
    "#display(Y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1 d) [OPTIONAL] Plot feature distributions. This step should give you clues about data sufficiency. (This question is not graded, it's intended for your reference only.)***\n",
    "\n",
    "Your plotted image should look like this:\n",
    "\n",
    "<img src=\"assets/q1d_expected.png\" width=\"400\" /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature-scaling'></a>\n",
    "## 2. Classification with Feature Scaling\n",
    "- Labels are discrete values in classification tasks.\n",
    "- Here the model is trained to classify each instance into a set of predefined  discrete classes.\n",
    "- On inputting a feature vector into the model, the trained model is able to predict a  class of that instance. You can also output the probabilities of an instance belnging to a class.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2 a):  Bucket the response variable `Y1` (`Heating Load`) from the original dataset into 3 classes based on the ranges below. Save this new column in a `pd.Series` named `Y_class`. Then use `pd.Series.value_counts()` to see how many values are in each class.**\n",
    "\n",
    "- `Low` : (0, 14]  \n",
    "-  `Medium` : (14, 28]\n",
    "-  `High` :  (28, Inf]\n",
    "\n",
    "This converts the given dataset into a classification problem where the classes to predict are the heating load types (`Low`, `Medium`, `High`). We will use this new datset with the transformed heating load column to create a  logistic regression classification model. \n",
    "\n",
    "*HINT:* Use [`pandas.cut`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "Y_class = ...\n",
    "#Y_class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2 b) Split the dataset into training and test.**\n",
    "- Use test-train split ratio of 0.8 : 0.2 (`test_size = 0.2`) and `random_state = 100`\n",
    "- When initialize your logistic regression model set `max_iter = 1e4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 100 # Use this random state in your model\n",
    "test_size = 0.2\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "...\n",
    "\n",
    "#print ('Number of samples in training data:', len(x_train))\n",
    "#print ('Number of samples in validation data:', len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2 c) Fit two logistic regression models to the training data. One model should use Softmax Regression (multinomial) and the other should use the One-vs-Rest procedure.**\n",
    "\n",
    "- For both models, initialize your model with `max_iter = 1e4`\n",
    "- You can specify the type of multiclass logistic regression model by the `multi_class` parameter in `linear_model.LogisticRegression(...)`\n",
    "    - One-vs-Rest (One-vs-All): `multi_class = 'ovr'`\n",
    "    - Softmax Regression (Multinomial): `multi_class = 'multinomial'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Name our regression objects\n",
    "logreg_model_ovr = ...\n",
    "logreg_model_mult = ...\n",
    "\n",
    "# Fit the training data to our models\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2 d) Calculate the training and test accuracies for both the One-vs-Rest and Softmax Regression Models. (You should report a total of 4 accuracy measurements)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q2 e): Perform unity based normalization on the above dataset and train the model again. You will compare the performance of the models trained on scaled data with the training and test accuracies of your original model.__  \n",
    "\n",
    "One of the preprocessing steps in Data science is Feature Scaling i.e getting all our data on the same scale by setting same Min-Max of feature values. \n",
    "This makes training less sensitive to the scale of features . \n",
    "Scaling is important in algorithms that use distance based classification, SVM or K means or those that involve gradient descent optimization. If we  scale features in the range [0,1] it is called unity based normalization or Min-Max scaling.\n",
    "\n",
    "Refer: http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler  \n",
    "More at: https://en.wikipedia.org/wiki/Feature_scaling\n",
    "\n",
    "In this question, you will be comparing the performance of the Min-Max Scaler to the Standard Normal Scaler. You should use the same training and test split from **Q2 b**. Follow the guidelines below:\n",
    "\n",
    "1. You should create two transformed `X` datasets. Scale (transform) `X` with the Min-Max Scaler. Save this dataset as `X_minmax_scaler`\n",
    "2. Scale `X` by the Standard Normal Scaler and save this dataset as `X_std_scaled`\n",
    "3. Split `X_minmax_scaled` and `X_std_scaled` using the same parameters: `random_state = 100` and `test_size = 0.2`\n",
    "4. Initialize, train and fit separate models for each scaler. Use `max_iter=1e4` and `multi_class = multinomial`\n",
    "5. Report the both the Training and Test Accuracy for each of the two scalers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='confusion-matrices'></a>\n",
    "## 3. Precision, Recall, and Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will be training a logistic regression model to classify handwritten digits. SciKit learn has a collection of ready-to-use datasets which we will use here.\n",
    "Parts of this questions were drawn from: https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in this dataset: 1797\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "print('Images in this dataset: %i' % len(digits.images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question, we'll access the following attributes of `digits`:\n",
    "- `digits.images`: All the images stored as 8x8 arrays.\n",
    "- `digits.data`: All the images stored as 1x64 arrays. (The images have been \"flattened\" so we can train our model.)\n",
    "- `digits.target`: The label for each of the images. (The first label corresponds to the first image in `digits.images` and `digits.data` and the second matches the second image and so on...)\n",
    "- `target_names`: List of unique labels (i.e. 0, 1, 2 ... 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is stored as an 8x8 array. When building our model we will use the flattened 1x64 array representation, but for now let's look at an 8x8 array. The first image in the data set is stored as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 0's correspond to white squares and the higher numbers correspond to darker squares. The first image looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(digits.images[0], cmap=plt.cm.gray_r, interpolation='nearest');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first 10 handwritten digits in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 10,figsize=(20,20))\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for ax, (image, label) in zip(axes.reshape(10,), images_and_labels[:10]):\n",
    "    #ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('Label: %i' % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3 a):  Create a histogram to show how many images exist for each label in the dataset. Does there appear to be an even distribution of labels?**\n",
    "\n",
    "*HINT:* Use `digits.target` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3 b)  Train a logistic regression model to classify the images. Use the following parameters.**\n",
    "1. Split the data into training and test sets. Use `random_state=100` and `test_size=0.90`. (Note: Our model we be fairly good, so we can use a small training set.)\n",
    "2. Intialize and fit a logistic regression model using `max_iter=1e4` and `multi_class = 'multinomial'`\n",
    "3. Report the training and test accuracies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split the train and testing data\n",
    "random_state=100 # don't change these lines\n",
    "test_size=0.90 # don't change these lines\n",
    "\n",
    "X = digits.data\n",
    "Y = digits.target\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3 c)  Create a confusion matrix for the logistic regression model you created in the previous question. From visually inspecting the confusion matrix, which digit does the model appear to have the hardest time classifying (i.e. digit with the least correctly labeled instances)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3 d) What is the proportion of images with a *predicted* label of `1` that have the correct label? Is this precision or recall?**\n",
    "\n",
    "*HINT*: Use [`sklearn.metrics.classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the image labels on the test set\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3 e) What is the proportion of images with an *actual* label of `8` that have the correct label? Is this precision or recall?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ANSWER HERE*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
