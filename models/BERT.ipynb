{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"BERT.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IQVsXpfTZTKm"},"source":["# Setup"]},{"cell_type":"code","metadata":{"id":"1rqR68qvZbTv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606529218413,"user_tz":480,"elapsed":2359,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}},"outputId":"1f9028f2-eaa1-49de-9716-ea0eecf09eeb"},"source":["pip install bert-tensorflow==1.0.1"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: bert-tensorflow==1.0.1 in /usr/local/lib/python3.6/dist-packages (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow==1.0.1) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"51lvE-R9bWQW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606529218569,"user_tz":480,"elapsed":2465,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}},"outputId":"4cfcdbbd-6d45-4363-87e7-7c3e011570cf"},"source":["%tensorflow_version 1.x"],"execution_count":4,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ckGAcRvVZTKm","executionInfo":{"status":"ok","timestamp":1606529219648,"user_tz":480,"elapsed":3525,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}},"outputId":"ba499700-40ea-4156-8766-168aeb9540dd"},"source":["from google.colab import drive\n","import numpy as np\n","import pandas as pd\n","import collections\n","import os\n","\n","\n","import tensorflow as tf\n","from datetime import datetime\n","\n","from bert import tokenization\n","from bert import modeling\n","from bert import optimization"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QJp6uj25ZXg-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606529219650,"user_tz":480,"elapsed":3510,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}},"outputId":"028d0c8d-f42a-40b2-b52d-7558b1bd4e57"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mJSCwhNOaIn9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606529219652,"user_tz":480,"elapsed":3488,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}},"outputId":"6cd180a7-a0e0-4483-bc98-86180dd8626f"},"source":["%cd drive/My Drive/Data-X: GGWP Toxic Behavior Public Data/Models"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Data-X: GGWP Toxic Behavior Public Data/Models\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f364x2BbZTKo","executionInfo":{"status":"ok","timestamp":1606529219654,"user_tz":480,"elapsed":3474,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["bert_vocab = './BERT Files/vocab.txt'\n","bert_init_checkpnt = './BERT Files/bert_model.ckpt'\n","bert_config_file = './BERT Files/bert_config.json'"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1sScc0VfZTKo","executionInfo":{"status":"ok","timestamp":1606529220416,"user_tz":480,"elapsed":4227,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["train_data_path = '../Data/train[1].csv'\n","train_data = pd.read_csv(train_data_path)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"P7q-Z0qLZTKo","colab":{"base_uri":"https://localhost:8080/","height":202},"executionInfo":{"status":"ok","timestamp":1606529220417,"user_tz":480,"elapsed":4216,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}},"outputId":"efe769db-e7f9-4369-a6d0-f959281868c5"},"source":["train_data.head()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0000997932d777bf</td>\n","      <td>Explanation\\nWhy the edits made under my usern...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>000103f0d9cfb60f</td>\n","      <td>D'aww! He matches this background colour I'm s...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>000113f07ec002fd</td>\n","      <td>Hey man, I'm really not trying to edit war. It...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0001b41b1c6bb37e</td>\n","      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0001d958c54c6e35</td>\n","      <td>You, sir, are my hero. Any chance you remember...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 id  ... identity_hate\n","0  0000997932d777bf  ...             0\n","1  000103f0d9cfb60f  ...             0\n","2  000113f07ec002fd  ...             0\n","3  0001b41b1c6bb37e  ...             0\n","4  0001d958c54c6e35  ...             0\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"cw9Yfv59ZTKp","executionInfo":{"status":"ok","timestamp":1606529220419,"user_tz":480,"elapsed":4207,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["label_columns = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cG9Y6QXzZTKp"},"source":["## Setup Tokenizer"]},{"cell_type":"code","metadata":{"id":"Bgf_fQmwZTKp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606529220642,"user_tz":480,"elapsed":4418,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}},"outputId":"a0cc9719-eef7-4dd0-8ebf-b4c8775406e0"},"source":["tokenization.validate_case_matches_checkpoint(True, bert_init_checkpnt)\n","tokenizer = tokenization.FullTokenizer(vocab_file=bert_vocab, do_lower_case=True)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7q3_cMZDZTKp"},"source":["## Input Example and Feature Classes"]},{"cell_type":"code","metadata":{"id":"RYrYR4KLZTKp","executionInfo":{"status":"ok","timestamp":1606529220644,"user_tz":480,"elapsed":4406,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["class InputExample(object):\n","    \"\"\"\n","    Single training/test example\n","    \"\"\"\n","    \n","    def __init__(self, guid, text_a, text_b=None, labels=None):\n","        \"\"\"\n","        Constructs Object of InputExample\n","\n","        Args:\n","            guid (string): Unique id\n","            text_a (string): Untokenized text of the first sequence\n","            text_b (string, optional): Untokenized text of the second sequence\n","            labels (string, optional)\n","        \"\"\"\n","        \n","        self.guid = guid\n","        self.text_a = text_a\n","        self.text_b = text_b\n","        self.labels = labels\n","        \n","\n","class PaddingInputExample(object):\n","    \"\"\"\n","    Fake Padding example used to make sure that the number of examples\n","    match the batch sizes. \n","    \"\"\"\n","        \n","        \n","class InputFeatures(object):\n","    \"\"\"\n","    Single Set of Features of Data\n","    \"\"\"\n","    \n","    def __init__(self, input_ids, input_mask, segment_ids, label_ids, is_real_example=True):\n","        \"\"\"\n","        Constructs Object of InputFeatures\n","        \n","        Args:\n","            input_ids (List(string)): Ids of Tokens\n","            input_mask (List(int)): Mask to determine whether it is a real token or padding\n","            segment_ids (List(int)): Ids of Segments. 0 is tokens_a, 1 is tokens_b (sequence pair)\n","            label_ids (List(int)): Ids of labels\n","            is_real_example (boolean): Is real example or padding\n","        \"\"\"\n","        \n","        self.input_ids = input_ids\n","        self.input_mask = input_mask\n","        self.segment_ids = segment_ids\n","        self.label_ids = label_ids\n","        self.is_real_example = is_real_example"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Vstd-y4ZTKp"},"source":["## Feature Builders "]},{"cell_type":"code","metadata":{"id":"_gVqZJCjZTKp","executionInfo":{"status":"ok","timestamp":1606529220646,"user_tz":480,"elapsed":4395,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["def convert_single_example(example,  max_seq_length, tokenizer):\n","    \"\"\"\n","    Converts a 'InputExample' into 'InputFeatures'\n","    \"\"\"\n","    \n","    def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n","        \"\"\"\n","        Truncates a sequence pair so that it'll have max_length\n","        \"\"\"\n","        \n","        while True:\n","            total_length = len(tokens_a) + len(tokens_b)\n","            if total_length <= max_length:\n","                break\n","            if len(tokens_a) > len(tokens_b):\n","                tokens_a.pop()\n","            else:\n","                tokens_b.pop()\n","    \n","    if isinstance(example, PaddingInputExample):\n","        return InputFeatures(\n","            input_ids=[0] * max_seq_length,\n","            input_mask=[0] * max_seq_length,\n","            segment_ids=[0] * max_seq_length,\n","            label_id=0,\n","            is_real_example=False)\n","    \n","    tokens_a = tokenizer.tokenize(example.text_a)\n","\n","    tokens_b = None\n","    if example.text_b:\n","        tokens_b = tokenizer.tokenize(example.text_b)\n","        # length is less than the specified length.\n","        # Account for [CLS], [SEP], [SEP] with \"- 3\"\n","        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n","    else:\n","        # Account for [CLS] and [SEP] with \"- 2\"\n","        if len(tokens_a) > max_seq_length - 2:\n","            tokens_a = tokens_a[:(max_seq_length - 2)]\n","    \n","    # Sandwich token_a with [CLS] and [SEP] and append to tokens\n","    tokens = ['[CLS]'] + tokens_a + ['[SEP]']\n","    segment_ids = [0] * len(tokens)\n","\n","    # If token_b, then add to token  and append [SEP]\n","    if tokens_b:\n","        tokens += tokens_b + ['[SEP]']\n","        segment_ids += [1] * (len(tokens_b) + 1)\n","    \n","    # Get Input Ids based on Token\n","    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","    # 1 for Real tokens, 0 for Padding\n","    input_mask = [1] * len(input_ids)\n","\n","    # Zero-pad up to the sequence length\n","    padding = [0] * (max_seq_length - len(input_ids))\n","    input_ids += padding\n","    input_mask += padding\n","    segment_ids += padding\n","\n","    assert len(input_ids) == max_seq_length\n","    assert len(input_mask) == max_seq_length\n","    assert len(segment_ids) == max_seq_length\n","    \n","    # Add Label Ids\n","    labels_ids = []\n","    for label in example.labels:\n","        labels_ids.append(int(label))\n","\n","    feature = InputFeatures(input_ids=input_ids,\n","                          input_mask=input_mask,\n","                          segment_ids=segment_ids,\n","                          label_ids=labels_ids)\n","    \n","    return feature"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"ce-hXmwuZTKp","executionInfo":{"status":"ok","timestamp":1606529220651,"user_tz":480,"elapsed":4389,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["def file_based_convert_examples_to_features(examples, max_seq_length, tokenizer, output_file):\n","    \"\"\"\n","    Convert a list of `InputExample`s to a TFRecord file.\n","    \"\"\"\n","    \n","    def create_int_feature(values):\n","        \"\"\"\n","        Converts feature into Int64List\n","        \"\"\"\n","        f = tf.train.Feature(int64_list=tf.train.Int64List(value=list(values)))\n","        return f\n","    \n","    writer = tf.io.TFRecordWriter(output_file)\n","\n","    for ex_index, example in enumerate(examples):\n","        if ex_index % 10000 == 0:\n","            tf.compat.v1.logging.info(f\"Writing example {ex_index} of {len(examples)}\")\n","\n","        feature = convert_single_example(example, max_seq_length, tokenizer)\n","        \n","        features = collections.OrderedDict()\n","        features['input_ids'] = create_int_feature(feature.input_ids)\n","        features['input_mask'] = create_int_feature(feature.input_mask)\n","        features['segment_ids'] = create_int_feature(feature.segment_ids)\n","        features['label_ids'] = create_int_feature(feature.label_ids)\n","        features['is_real_example'] = create_int_feature([int(feature.is_real_example)])\n","\n","        tf_example = tf.train.Example(features=tf.train.Features(feature=features))\n","        writer.write(tf_example.SerializeToString())\n","        \n","    writer.close()"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"jBlJ4JCSZTKp","executionInfo":{"status":"ok","timestamp":1606529220653,"user_tz":480,"elapsed":4381,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["def convert_examples_to_features(examples, max_seq_length, tokenizer):\n","    \"\"\"\n","    Convert a list of `InputExample`s to a list of `InputFeatures`.\n","    \"\"\"\n","\n","    features = []\n","    for ex_index, example in enumerate(examples):\n","        if ex_index % 10000 == 0:\n","            tf.compat.v1.logging.info(f\"Writing example {ex_index} of {len(examples)}\")\n","\n","        feature = convert_single_example(example, max_seq_length, tokenizer)\n","        features.append(feature)\n","        \n","    return features"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JuU8qNVcZTKp"},"source":["## Input_fn Builders"]},{"cell_type":"code","metadata":{"id":"lnUjhhUEZTKp","executionInfo":{"status":"ok","timestamp":1606529220654,"user_tz":480,"elapsed":4371,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["def file_based_input_fn_builder(input_file, seq_length, is_training, drop_remainder):\n","    \"\"\"\n","    Creates an `input_fn` closure to be passed to TPUEstimator using a TFRecord file.\n","    \"\"\"\n","\n","    name_to_features = {\n","        \"input_ids\": tf.io.FixedLenFeature([seq_length], tf.int64),\n","        \"input_mask\": tf.io.FixedLenFeature([seq_length], tf.int64),\n","        \"segment_ids\": tf.io.FixedLenFeature([seq_length], tf.int64),\n","        \"label_ids\": tf.io.FixedLenFeature([6], tf.int64),\n","        \"is_real_example\": tf.io.FixedLenFeature([], tf.int64),\n","    }\n","\n","    def _decode_record(record, name_to_features):\n","        \"\"\"\n","        Decodes a record to a TensorFlow example.\n","        \"\"\"\n","        example = tf.parse_single_example(record, name_to_features)\n","\n","        # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n","        # So cast all int64 to int32.\n","        for name in list(example.keys()):\n","            t = example[name]\n","            if t.dtype == tf.int64:\n","                t = tf.to_int32(t)\n","            example[name] = t\n","\n","        return example\n","\n","    def input_fn(params):\n","        \"\"\"\n","        The actual input function.\n","        \"\"\"\n","        batch_size = params[\"batch_size\"]\n","\n","        # For training, we want a lot of parallel reading and shuffling.\n","        # For eval, we want no shuffling and parallel reading doesn't matter.\n","        d = tf.data.TFRecordDataset(input_file)\n","        if is_training:\n","            d = d.repeat()\n","            d = d.shuffle(buffer_size=100)\n","\n","        d = d.apply(\n","            tf.contrib.data.map_and_batch(\n","                lambda record: _decode_record(record, name_to_features),\n","                batch_size=batch_size,\n","                drop_remainder=drop_remainder))\n","\n","        return d\n","\n","    return input_fn"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"3pwsNxbUZTKp","executionInfo":{"status":"ok","timestamp":1606529220655,"user_tz":480,"elapsed":4359,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["def input_fn_builder(features, seq_length, is_training, drop_remainder):\n","    \"\"\"\n","    Creates an `input_fn` closure to be passed to TPUEstimator using a list of features.\n","    \"\"\"\n","\n","    all_input_ids = []\n","    all_input_mask = []\n","    all_segment_ids = []\n","    all_label_ids = []\n","\n","    for feature in features:\n","        all_input_ids.append(feature.input_ids)\n","        all_input_mask.append(feature.input_mask)\n","        all_segment_ids.append(feature.segment_ids)\n","        all_label_ids.append(feature.label_ids)\n","\n","    def input_fn(params):\n","        \"\"\"The actual input function.\"\"\"\n","        batch_size = params[\"batch_size\"]\n","\n","        num_examples = len(features)\n","\n","        d = tf.data.Dataset.from_tensor_slices({\n","            \"input_ids\":\n","                tf.constant(\n","                    all_input_ids, shape=[num_examples, seq_length],\n","                    dtype=tf.int32),\n","            \"input_mask\":\n","                tf.constant(\n","                    all_input_mask,\n","                    shape=[num_examples, seq_length],\n","                    dtype=tf.int32),\n","            \"segment_ids\":\n","                tf.constant(\n","                    all_segment_ids,\n","                    shape=[num_examples, seq_length],\n","                    dtype=tf.int32),\n","            \"label_ids\":\n","                tf.constant(all_label_ids, shape=[num_examples, len(label_columns)], dtype=tf.int32),\n","        })\n","\n","        if is_training:\n","            d = d.repeat()\n","            d = d.shuffle(buffer_size=100)\n","\n","        d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n","        return d\n","\n","    return input_fn"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TgjerFKcZTKp"},"source":["## Model_fn Builders"]},{"cell_type":"code","metadata":{"id":"cnuYGwNxZTKp","executionInfo":{"status":"ok","timestamp":1606529220656,"user_tz":480,"elapsed":4347,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["def create_model(bert_config, is_training, input_ids, input_mask, segment_ids, \n","                 labels, num_labels, use_one_hot_embeddings):\n","    \"\"\"\n","    Creates the multi-label clsasification model.\n","    \"\"\"\n","    \n","    model = modeling.BertModel(\n","        config=bert_config,\n","        is_training=is_training,\n","        input_ids=input_ids,\n","        input_mask=input_mask,\n","        token_type_ids=segment_ids,\n","        use_one_hot_embeddings=use_one_hot_embeddings)\n","\n","    \n","    output_layer = model.get_pooled_output()\n","\n","    hidden_size = output_layer.shape[-1].value\n","    \n","    # Creates a variable \"output_weights\" in the tensorflow graph\n","    output_weights = tf.get_variable(\n","        \"output_weights\", [num_labels, hidden_size],\n","        initializer=tf.truncated_normal_initializer(stddev=0.02))\n","    \n","    # Creates a variable \"output_bias\" in the tensorflow graph\n","    output_bias = tf.get_variable(\n","        \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n","    \n","    # Create Variable 'loss'\n","    with tf.variable_scope(\"loss\"):\n","        if is_training:\n","            # 0.1 dropout Layer\n","            output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n","        \n","        # Multiplies output layer by output weights\n","        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n","        \n","        # Adds bias\n","        logits = tf.nn.bias_add(logits, output_bias)\n","        \n","        # Sigmoid used since multilabel. Softmax will make it so then\n","        # all probabilities of each label add to 1\n","        probabilities = tf.nn.sigmoid(logits)\n","        \n","        labels = tf.cast(labels, tf.float32)\n","        tf.compat.v1.logging.info(f\"num_labels:{num_labels};logits:{logits};labels:{labels}\")\n","        \n","        # Sigmoid cross entropy used for multilabel\n","        per_example_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n","        loss = tf.reduce_mean(per_example_loss)\n","\n","        return loss, per_example_loss, logits, probabilities\n","        "],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"_G8X3MIsZTKp","executionInfo":{"status":"ok","timestamp":1606529220920,"user_tz":480,"elapsed":4599,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["def model_fn_builder(bert_config, num_labels, init_checkpoint, learning_rate,\n","                     num_train_steps, num_warmup_steps, use_tpu,\n","                     use_one_hot_embeddings):\n","    \"\"\"\n","    Returns `model_fn` closure for TPUEstimator.\n","    \"\"\"\n","\n","    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n","        \"\"\"\n","        The `model_fn` for TPUEstimator.\n","        \"\"\"\n","        \n","        tf.compat.v1.logging.info(\"*** Features ***\")\n","        for name in sorted(features.keys()):\n","            tf.compat.v1.logging.info(f\"  name = {name}, shape = {features[name].shape}\")\n","        \n","        input_ids = features[\"input_ids\"]\n","        input_mask = features[\"input_mask\"]\n","        segment_ids = features[\"segment_ids\"]\n","        label_ids = features[\"label_ids\"]\n","        is_real_example = None\n","        if \"is_real_example\" in features:\n","             is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n","        else:\n","             is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n","\n","        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n","        \n","        # Create Model\n","        total_loss, per_example_loss, logits, probabilities = create_model(\n","            bert_config, is_training, input_ids, input_mask, segment_ids, label_ids,\n","            num_labels, use_one_hot_embeddings)\n","\n","        tvars = tf.trainable_variables()\n","        initialized_variable_names = {}\n","        scaffold_fn = None\n","        # If loading from checkpoint\n","        if init_checkpoint:\n","            assignment_map, initialized_variable_names = \\\n","            modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n","            \n","            if use_tpu:\n","                def tpu_scaffold():\n","                    tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n","                    return tf.train.Scaffold()\n","\n","                scaffold_fn = tpu_scaffold\n","            else:\n","                tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n","\n","        tf.compat.v1.logging.info(\"**** Trainable Variables ****\")\n","        for var in tvars:\n","            init_string = \"\"\n","            if var.name in initialized_variable_names:\n","                init_string = \", *INIT_FROM_CKPT*\"\n","            tf.compat.v1.logging.info(f\"  name = {var.name}, shape = {var.shape}{init_string}\")\n","        \n","        output_spec = None\n","        if mode == tf.estimator.ModeKeys.TRAIN:\n","\n","            train_op = optimization.create_optimizer(\n","                total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n","\n","            output_spec = tf.estimator.EstimatorSpec(\n","                mode=mode,\n","                loss=total_loss,\n","                train_op=train_op,\n","                scaffold=scaffold_fn)\n","        elif mode == tf.estimator.ModeKeys.EVAL:\n","\n","            def metric_fn(per_example_loss, label_ids, probabilities, is_real_example):\n","                \"\"\"\n","                Metric Function - AUC of Every Class\n","                \"\"\"\n","                logits_split = tf.split(probabilities, num_labels, axis=-1)\n","                label_ids_split = tf.split(label_ids, num_labels, axis=-1)\n","                eval_dict = {}\n","                for j, logits in enumerate(logits_split):\n","                    label_id_ = tf.cast(label_ids_split[j], dtype=tf.int32)\n","                    current_auc, update_op_auc = tf.metrics.auc(label_id_, logits)\n","                    eval_dict[\"eval_AUC_\" + str(j)] = (current_auc, update_op_auc)\n","                eval_dict['eval_loss'] = tf.metrics.mean(values=per_example_loss)\n","                return eval_dict\n","\n","            eval_metrics = metric_fn(per_example_loss, label_ids, probabilities, is_real_example)\n","            output_spec = tf.estimator.EstimatorSpec(\n","                mode=mode,\n","                loss=total_loss,\n","                eval_metric_ops=eval_metrics,\n","                scaffold=scaffold_fn)\n","        else:\n","            print(\"mode:\", mode,\"probabilities:\", probabilities)\n","            output_spec = tf.estimator.EstimatorSpec(\n","                mode=mode,\n","                predictions={\"probabilities\": probabilities},\n","                scaffold=scaffold_fn)\n","        return output_spec\n","\n","    return model_fn"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b3SAUl0PZTKp"},"source":["# Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"48ivbRxuZTKp"},"source":["## Process Training Data"]},{"cell_type":"markdown","metadata":{"id":"XCsUb1kdZTKq"},"source":["## Data Configurations"]},{"cell_type":"code","metadata":{"id":"TRbj86SyZTKq","executionInfo":{"status":"ok","timestamp":1606529220922,"user_tz":480,"elapsed":4586,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["MAX_SEQ_LENGTH = 128\n","\n","# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n","BATCH_SIZE = 32\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 1.0\n","# Warmup is a period of time where hte learning rate \n","# is small and gradually increases--usually helps training.\n","WARMUP_PROPORTION = 0.1\n","# Model configs\n","SAVE_SUMMARY_STEPS = 500\n","SAVE_CHECKPOINTS_STEPS = 1000"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bYTnMpEWZTKq"},"source":["### Create Examples"]},{"cell_type":"code","metadata":{"id":"I3Cy3dM1ZTKq","executionInfo":{"status":"ok","timestamp":1606529220924,"user_tz":480,"elapsed":4572,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["def create_examples(df, labels_available=True):\n","    \"\"\"\n","    Create examples for the training and test sets\n","    \"\"\"\n","    examples = []\n","    for i, row in enumerate(df.values):\n","        guid = row[0]\n","        text_a = str(row[1])\n","        if labels_available:\n","            labels=row[2:]\n","        else:\n","            labels = [0] * 6\n","        \n","        examples.append(InputExample(guid=guid, text_a=text_a, labels=labels))\n","    \n","    return examples\n","    "],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZK4pbuBrZTKq","executionInfo":{"status":"ok","timestamp":1606529221295,"user_tz":480,"elapsed":4932,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["train_examples = create_examples(train_data)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLYCjwk4ZTKq","executionInfo":{"status":"ok","timestamp":1606529221300,"user_tz":480,"elapsed":4928,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["# Compute # train and warmup steps from batch size\n","num_train_steps = int(len(train_examples) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DKJxQBt4ZTKq"},"source":["### Convert to TFRecord"]},{"cell_type":"code","metadata":{"id":"wnlPL48yZTKq","executionInfo":{"status":"ok","timestamp":1606529221301,"user_tz":480,"elapsed":4920,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["train_file = os.path.join('./BERT Files/working', 'train.tf_record')\n","if not os.path.exists(train_file):\n","    open(train_file, 'w').close()"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JFKRjCITZTKq","executionInfo":{"status":"ok","timestamp":1606529399174,"user_tz":480,"elapsed":182781,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}},"outputId":"a564cea3-f346-4828-8c77-d7cf0052c34e"},"source":["file_based_convert_examples_to_features(\n","            train_examples, MAX_SEQ_LENGTH, tokenizer, train_file)\n","tf.compat.v1.logging.info(\"***** Running training *****\")\n","tf.compat.v1.logging.info(\"  Num examples = %d\", len(train_examples))\n","tf.compat.v1.logging.info(\"  Batch size = %d\", BATCH_SIZE)\n","tf.compat.v1.logging.info(\"  Num steps = %d\", num_train_steps)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 159571\n","INFO:tensorflow:Writing example 10000 of 159571\n","INFO:tensorflow:Writing example 20000 of 159571\n","INFO:tensorflow:Writing example 30000 of 159571\n","INFO:tensorflow:Writing example 40000 of 159571\n","INFO:tensorflow:Writing example 50000 of 159571\n","INFO:tensorflow:Writing example 60000 of 159571\n","INFO:tensorflow:Writing example 70000 of 159571\n","INFO:tensorflow:Writing example 80000 of 159571\n","INFO:tensorflow:Writing example 90000 of 159571\n","INFO:tensorflow:Writing example 100000 of 159571\n","INFO:tensorflow:Writing example 110000 of 159571\n","INFO:tensorflow:Writing example 120000 of 159571\n","INFO:tensorflow:Writing example 130000 of 159571\n","INFO:tensorflow:Writing example 140000 of 159571\n","INFO:tensorflow:Writing example 150000 of 159571\n","INFO:tensorflow:***** Running training *****\n","INFO:tensorflow:  Num examples = 159571\n","INFO:tensorflow:  Batch size = 32\n","INFO:tensorflow:  Num steps = 4986\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N93IkbVlZTKq"},"source":["### Convert to Input_fn"]},{"cell_type":"code","metadata":{"id":"SSf1UJKHZTKq","executionInfo":{"status":"ok","timestamp":1606529399177,"user_tz":480,"elapsed":182774,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["train_input_fn = file_based_input_fn_builder(\n","    input_file=train_file,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=True,\n","    drop_remainder=True)"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E84sU8geZTKq"},"source":["# Train Model"]},{"cell_type":"markdown","metadata":{"id":"j9lSsp3QZTKq"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"xyuyvC4RZTKq","executionInfo":{"status":"ok","timestamp":1606529399179,"user_tz":480,"elapsed":182766,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["output_dir = './BERT Files/working/output'\n","\n","# Specify output directory and number of checkpoint steps to save\n","run_config = tf.estimator.RunConfig(\n","    model_dir=output_dir,\n","    save_summary_steps=SAVE_SUMMARY_STEPS,\n","    keep_checkpoint_max=1,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0ombu0P6ZTKq"},"source":["## Train Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cnKt_6z0ZTKq","executionInfo":{"status":"ok","timestamp":1606529399181,"user_tz":480,"elapsed":182755,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}},"outputId":"5f8b93e2-69fe-422c-f646-a71e3265fff6"},"source":["bert_config = modeling.BertConfig.from_json_file(bert_config_file)\n","model_fn = model_fn_builder(\n","  bert_config=bert_config,\n","  num_labels= len(label_columns),\n","  init_checkpoint=bert_init_checkpnt,\n","  learning_rate=LEARNING_RATE,\n","  num_train_steps=num_train_steps,\n","  num_warmup_steps=num_warmup_steps,\n","  use_tpu=False,\n","  use_one_hot_embeddings=False)\n","\n","estimator = tf.estimator.Estimator(\n","  model_fn=model_fn,\n","  config=run_config,\n","  params={\"batch_size\": BATCH_SIZE})"],"execution_count":29,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': './BERT Files/working/output', '_tf_random_seed': None, '_save_summary_steps': 500, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdd70eb6ef0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YzdPFFf6ZTKq","executionInfo":{"status":"ok","timestamp":1606529399183,"user_tz":480,"elapsed":182740,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}},"outputId":"1c21d462-a186-4277-a6d0-f2ff8411a9dc"},"source":["print(f'Beginning Training!')\n","current_time = datetime.now()\n","estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","print(\"Training took time \", datetime.now() - current_time)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Beginning Training!\n","INFO:tensorflow:Skipping training since max_steps has already saved.\n","Training took time  0:00:00.015991\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"24xa-Dt8ZTKq"},"source":["## Evaluate Model"]},{"cell_type":"code","metadata":{"id":"GU2iBzbsHJiy"},"source":["val_data = pd.read_csv('../Data/combined.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_X4gta2ZTKq"},"source":["eval_file = os.path.join('./BERT Files/working', \"eval.tf_record\")\n","if not os.path.exists(eval_file):\n","    open(eval_file, 'w').close()\n","\n","eval_examples = create_examples(val_data)\n","file_based_convert_examples_to_features(\n","    eval_examples, MAX_SEQ_LENGTH, tokenizer, eval_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n4Q4_T0GZTKr"},"source":["# This tells the estimator to run through the entire validation set.\n","eval_steps = None\n","\n","eval_drop_remainder = False\n","eval_input_fn = file_based_input_fn_builder(\n","    input_file=eval_file,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=False,\n","    drop_remainder=False)\n","\n","result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bL-yC_bZZTKr"},"source":["output_eval_file = os.path.join(\"./BERT Files/working\", \"eval_results.txt\")\n","if not os.path.exists(output_eval_file):\n","    open(output_eval_file, 'w').close()\n","\n","with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n","    tf.compat.v1.logging.info(\"***** Eval results *****\")\n","    for key in sorted(result.keys()):\n","        tf.compat.v1.logging.info(\"  %s = %s\", key, str(result[key]))\n","        writer.write(\"%s = %s\\n\" % (key, str(result[key])))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W_oR0ozPZTKr"},"source":["## Make Predictions"]},{"cell_type":"code","metadata":{"id":"QGeSjbs8ZTKr","executionInfo":{"status":"ok","timestamp":1606529757064,"user_tz":480,"elapsed":350,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["def create_output(predictions, num_examples):\n","    probabilities = []\n","    for i, prediction in enumerate(predictions):\n","        if i % 1000 == 0:\n","            print(f\"Making predictions for {i} out of {num_examples}\")\n","        preds = prediction[\"probabilities\"]\n","        probabilities.append(preds)\n","    df = pd.DataFrame(probabilities)\n","    df.columns = label_columns\n","    \n","    return df"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"oMXHOOLWZTKr","executionInfo":{"status":"ok","timestamp":1606529757613,"user_tz":480,"elapsed":865,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["game_platform = 'pubg_twitter'\n","predict_data_path = '../Data/scraped/' + game_platform + '.csv'\n","data_predict = pd.read_csv(predict_data_path)\n","predict_examples = create_examples(data_predict, False)"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"9iN4FdhmZTKr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606529759775,"user_tz":480,"elapsed":3013,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}},"outputId":"e8f1569c-9488-4574-997f-3ca85932b5d2"},"source":["predict_features = convert_examples_to_features(predict_examples, MAX_SEQ_LENGTH, tokenizer)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 6081\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0xfSE7orZTKr","executionInfo":{"status":"ok","timestamp":1606529759779,"user_tz":480,"elapsed":3001,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["predict_input_fn = input_fn_builder(features=predict_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n","predictions = estimator.predict(predict_input_fn)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"cg_SatrSZTKr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606529824495,"user_tz":480,"elapsed":67704,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}},"outputId":"1d153015-5f20-4dd4-8984-ffd98db3ff93"},"source":["print('Beginning Predictions!')\n","current_time = datetime.now()\n","\n","output_df = create_output(predictions, len(predict_examples))\n","merged_df =  pd.concat([data_predict, output_df], axis=1)\n","merged_df = merged_df.set_index(merged_df.columns[0])\n","merged_df.index = merged_df.index.rename('')\n","print(\"Prediction took time \", datetime.now() - current_time)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Beginning Predictions!\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (?, 128)\n","INFO:tensorflow:  name = input_mask, shape = (?, 128)\n","INFO:tensorflow:  name = label_ids, shape = (?, 6)\n","INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n","INFO:tensorflow:num_labels:6;logits:Tensor(\"loss/BiasAdd:0\", shape=(?, 6), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(?, 6), dtype=float32)\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (6, 768)\n","INFO:tensorflow:  name = output_bias:0, shape = (6,)\n","mode: infer probabilities: Tensor(\"loss/Sigmoid:0\", shape=(?, 6), dtype=float32)\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Graph was finalized.\n","INFO:tensorflow:Restoring parameters from ./BERT Files/working/output/model.ckpt-4986\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","Making predictions for 0 out of 6081\n","Making predictions for 1000 out of 6081\n","Making predictions for 2000 out of 6081\n","Making predictions for 3000 out of 6081\n","Making predictions for 4000 out of 6081\n","Making predictions for 5000 out of 6081\n","Making predictions for 6000 out of 6081\n","Prediction took time  0:01:04.686385\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-aSUGwXl5HMK","executionInfo":{"status":"ok","timestamp":1606529824498,"user_tz":480,"elapsed":67693,"user":{"displayName":"Chris Lai","photoUrl":"","userId":"03264767088208040317"}}},"source":["output_name = 'predicted_' + game_platform + '.csv'\n","merged_df.to_csv('../Data/predicted/' + output_name)"],"execution_count":42,"outputs":[]}]}